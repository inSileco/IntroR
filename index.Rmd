---
title: "Introduction to R"
author: "Marie-Hélène Brice & Kevin Cazelles"
date: "2019/26/03"
output:
  xaringan::moon_reader:
    includes:
      in_header: inSileco-header.html
    lib_dir: assets
    seal: false
    css: ["default", "inSileco.css", "inSileco-fonts.css"]
    nature:
      beforeInit: "inSileco-macros.js"
---



```{r setup, echo = FALSE}
## Setup for your presentation
library(knitr)

opts_chunk$set(
  eval = TRUE,
  cache = FALSE,
  comment = "#",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width=5, fig.height=5,
  dpi = 300,
  fig.align = 'center'
)


hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})

options(width = 92)
```

```{r, echo = F}
mypar = list(mar = c(3,3,1,0.5), mgp = c(1.6, 0.3, 0), tck = -.02, cex = 1.5)

options(repos=structure(c(CRAN="http://cran.r-project.org")))
knitr::read_chunk("scripts/code_R.R")
```

```{r, include = FALSE}
library(vegan)
library(ade4)
library(scales)
library(tidyverse)
```


<br><br><br>

.maintitle[<i class="fa fa-angle-double-right" aria-hidden="true"></i>intRoduction]
<hr>

<br>


### Marie-Hélène Brice
### Kevin Cazelles

#### UQAM - March 26th, 2019 -- [<i class="fa fa-github" aria-hidden="true"></i>](https://github.com/inSileco/IntroR)


.right[
  ![:scale 20%](images/inSilecoLogo.png)
  ![:scale 20%](images/Rlogo.png)
  ]

---
# Aims

<br>

### &nbsp; Better ideas about what R actually is
### &nbsp; Better ideas about what R can do
### &nbsp; Better ideas about the topics covered

---
# Outline

### &nbsp; <i class="fa fa-commenting-o" aria-hidden="true"></i> R? ~10min
### &nbsp; <i class="fa fa-wrench" aria-hidden="true"></i> Data manipulations ~1h15min
### &nbsp; <i class="fa fa-bar-chart" aria-hidden="true"></i> Data visualization (part1) ~30min
### &nbsp; <i class="fa fa-cutlery" aria-hidden="true"></i> Lunch break 12pm
### &nbsp; <i class="fa fa-bar-chart" aria-hidden="true"></i> Data visualization (part2) ~30min
### &nbsp; <i class="fa fa-map" aria-hidden="true"></i> mapping ~ 1h30
### &nbsp; <i class="fa fa-coffee" aria-hidden="true"></i> *coffee break* 3pm
### &nbsp; <i class="fa fa-sitemap" aria-hidden="true"></i> ordination ~1h30



---
class: inverse, center, middle

# R?

## <i class="fa fa-commenting-o" aria-hidden="true"></i>


---
# R

<br>

> R is a programming language and free software environment for statistical computing and graphics [...].

<br>

> The R language is widely used among statisticians and data miners for developing statistical software and data analysis.

[R (programming language) - Wikipedia](https://en.wikipedia.org/wiki/R_(programming_language)


---
# R is popular

.center[![:scale 85%](images/redmonk.png)]

[Python](https://www.python.org/) / [Julia](https://julialang.org/)


---
# R is popular among Biological Sciences

### For instance

1. Ecologists
2. Bioinformatics [(Bioconductor)](https://www.bioconductor.org/)
3. Medicine [<i class="fa fa-external-link" aria-hidden="true"></i>](https://r-medicine.com/)

--

### Why?

1. An incredible tool for statistics
2. Fairly accessible for non-programmer people
3. A very high diversity of packages
4. Improved workflow


---
# R is popular

.center[![:scale 72%](https://revolution-computing.typepad.com/.a/6a010534b1db25970b01b8d2594d25970c-800wi)]

[*CRAN now has 10,000 R packages* Revolutions. January, 2017](https://blog.revolutionanalytics.com/2017/01/cran-10000.html)

[MetaCRAN](https://www.r-pkg.org/) / [R Package Documentation](https://rdrr.io/)




---
# R, RStudio, Ropenscience?

### Main links

- [R project](https://www.r-project.org/)
- [CRAN](https://cran.r-project.org/)
- [RStudio](https://www.rstudio.com/)
- [rOpenSci](https://ropensci.org)

### Get reliable documentation

- [CRAN Manual & Contributed](https://cran.r-project.org/)
- [bookdown](https://bookdown.org/)
- [RStudio](https://www.rstudio.com/)
  - [Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/)
  - [Webinars](https://resources.rstudio.com/webinars)
- [QCBS](https://qcbsrworkshops.github.io/Workshops/)
- [DataCarpentery](https://datacarpentry.org/R-genomics/index.html)
- [<i class="fa fa-stack-overflow" aria-hidden="true"></i>](https://stackoverflow.com/questions/tagged/r)




---
class: inverse, center, middle

# Data manipulation

## <i class="fa fa-wrench" aria-hidden="true"></i>



---
# Let's start
<br>

- Open R console / R GUI / RStudio / ...

--

```R
getwd()
setwd("pasth2workingdirectory")
```

--

- Install the following packages

```R
install.packages(c("tidyverse", "sf", "raster", "mapview", "vegan", "ade4",
  "scales", "Rcolorbrewer"))
```

---
# R's principles
<br>


### 1. Everything in R is an object

### 2. Everything that happens in R is a function call

### 3. Interfaces to other software are part of R.


[Extending-R by Chambers](https://www.crcpress.com/Extending-R/Chambers/p/book/9781498775717)

---
# Everything in R is an object
<br>

```{R}
2
```

--

```{R}
class(2)
```
--

```{R}
class("A")
class(library)
plot
```

---
class: center
# Everything that happens in R is a function call
<br>

```R
class(2)
```
## <i class="fa fa-arrow-circle-o-down" aria-hidden="true"></i>

### `enter`

## <i class="fa fa-arrow-circle-o-down" aria-hidden="true"></i>

```{R, echo = FALSE}
class(2)
```


---
# Interfaces to other software are part of R
<br>

### Four examples among many others:

- [Rcpp](https://cran.r-project.org/web/packages/Rcpp/index.html)

- [Reticulate](https://rstudio.github.io/reticulate/index.html)

- [Rmarkdown](https://rmarkdown.rstudio.com/)

- [plotly](https://plot.ly/r/)

- [mapview](https://r-spatial.github.io/mapview/)


---
# Basic commands

```{R, basic1}
2+2
2*3
3>2
```

--

```{R, basic2}
let <- LETTERS[1:10]
let2 = LETTERS[1:10]
let
let2
identical(let, let2)
```

--
```{R, basic3}
let3 <- sample(let, 5)
let2
```

--

```R
# Functions documentation
?sample
```

---
# Vectors

**Create a vector**

```{R, basic4}
vec <- c(2:5, 9:12, 2)
vec
vec > 4
```

--

```{R, vec}
let
length(let)
```
--

**Subset a vector**

```{R, vec2}
let[1:2]
let[c(1:2, 5:6)]
let[-c(1,7)]
vec[vec > 4]
let[let > "C"]
```

---
# Matrices

```{R, mat}
# use arguments
mat <- matrix(1:18, ncol = 3, nrow = 6)
mat
dim(mat)
mat[1,2]
```
--

```{R, mat2}
mat[1,]
mat[,2]
mat[2:4, 1:2]
```

---
# Data frames

## &nbsp; &nbsp; <i class="fa fa-question-circle-o" aria-hidden="true"></i>

--

```{R, dataframe}
df <- data.frame(
  letter = let[1:5],
  val = vec[1:5],
  logic = vec[1:5]>2
)
df
class(df)
dim(df)
```

---
# Data frames

```{R, dataframe2}
df[1, 1]
```

```{R, dataframe3}
df$letter
df[,1]
df[1]
df[1:2]
```

```{R, dataframe4}
class(df$letter)
class(df$val)
```

---
# Data frames
<br>

```{R}
library(datasets)
```

To see the list of available datasets:

```R
data()
```

To access the documentation of a particular dataset:

```R
?CO2
```


---
# Data frames

```{R}
library(datasets)
head(CO2)
names(CO2)
summary(CO2)
```

--

```{R}
CO2$Plant
```


---
# Lists

```{R}
mylist <- list(CO2 = CO2, mymat = mat, mylet = let[1], awesome = "cool")
names(mylist)
mylist$awesome
mylist[3:4]
```

--

```{R}
class(mylist[2])
class(mylist[[2]])
mylist[[2]]
class(mylist[[2]][2,3])
mylist[[2]][2,3]
```


---
# For loops

```{R}
for (i in 1:4) {
  # actions
  print(i)
}
```

```{R}
for (j in LETTERS[1:5]) {
  print(j)
}
```

```{R}
for (i in c(1,4,6)) {
  print(i)
}
```


---
# Logical conditions &nbsp; > &nbsp; >= &nbsp; < &nbsp; <= &nbsp; == &nbsp; !=

--

```{R}
vec <- c(2:5, 9:12, 2)
vec
vec[1] > 4
vec > 4
```

--

`if` ... `else` ...

```{R}
for (i in vec) {
  if (i <= 5) {
   # actions
   print(i)
 } else {
   print("nope")
 }
}
```




---
class: inverse, center, middle

# Questions?

## <i class="fa fa-question-circle-o" aria-hidden="true"></i>


---
# Tidyverse - a metapackage

<br>


```{R, eval = F}
library(tidyverse)
```

### <i class="fa fa-wrench" aria-hidden="true"></i> A great tool belt for data science [<i class="fa fa-external-link" aria-hidden="true"></i>](https://www.tidyverse.org/)

--

- <i class="fa fa-check" aria-hidden="true"></i> Pros:
  - well-documented, intuitive
  - efficient
  - very popular

- <i class="fa fa-exclamation-triangle" aria-hidden="true"></i>Cons:
  - an alternative way of doing the same manipulation things
  - prevents the user from learning programming basics



---
# Data manipulations
<br>

### &nbsp; 1. Import data / read file(s) <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> get R object(s)
### &nbsp; 2. Select / Filter <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> find the data of interest
### &nbsp; 3. Join <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> combine data
### &nbsp; 4. Mutate / Aggregate <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> create new data
### &nbsp; 5. Cast and Melt <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> Format your data (see tidyr)
### &nbsp; 6. R object(s) <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> Export data / write file(s)



---
# Read a file

```{R, read}
df2 <- read.csv("data/environ.csv")
head(df2, 3)
class(df2)
```
--

```{R, readr}
df3 <- read_csv("data/environ.csv")
head(df3, 3)
class(df3)
```

--

- `read.table()`
- [SQL in R](http://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/sql.html)
- [MongoDB in R](https://jeroen.github.io/mongolite/)
- [MariaDB](https://mariadb.com/kb/en/library/r-statistical-programming-using-mariadb-as-the-background-database/)


---
# Doubs River Fish Dataset

<br>

.pull-left[

Verneaux (1973) dataset:
- characterization of fish communities
- 27 different species
- 30 different sites
- 11 environmental variables

Load the Doubs River species data

```{r}
library(ade4)
data(doubs)
# ?doubs
```

]

.pull.right[
![:scale 50%](images/DoubsRiver.png)
]


---
# Dataset 'doubs' in package 'ade4'
<br>


```{R}
class(doubs)
names(doubs)
head(doubs$env)
```


---
# Dataset 'doubs' in package 'ade4'
<br>

```{R}
as_tibble(doubs$env)
```

---
# Piping

--

```{R, pip1}
res <- as_tibble(data.frame(res = log(diff(exp(1:6)))))
res
```

--

```{R, pip2}
# library(magrittr)
res <- 1:6 %>% exp %>% diff %>% log %>% as.data.frame(col.names = "res") %>% as_tibble
res
```


---
# Select

--

```{R}
denv <- as_tibble(doubs$env)
dim(denv)
names(denv)
head(denv, 20)
```

---
# Select

```{R}
head(denv[, c(1:2, 5)])
head(denv[, c("dfs", "alt", "pH")])
```

---
# Select

```{R}
denvS <- denv %>% select(dfs, alt, pH)
head(denvS)
```

```{R}
denvS <- denv %>% select(alt, pH, dfs)
head(denvS)
```


---
# Select

```{R}
head(denv[, -c(1:2, 5)])
# head(denv[, -c("dfs", "alt", "pH")]) won't work
```

```{R}
denv %>% select(-dfs, -alt, -pH)
```


---
# Filter

```{R}
denv$alt
```

--

```{R, filter}
denvF <- denv %>% dplyr::filter(alt > 400)
denvF
```

---
# Filter
<br>

```{R}
denvF2 <- denv %>% dplyr::filter(alt > 400 & pH>=80)
denvF2
```

---
# Filter
<br>

```{R}
denvF3 <- denv %>% dplyr::filter(alt > 600 | pH>=82)
denvF3
```

---
# Filter
<br>

Selection + Filter

--

```{R}
denvF4 <- denv %>% select(dfs, alt, pH) %>% dplyr::filter(alt > 400 & pH>=80)
denvF4
```


---
# Mutate
<br>

--

```{R, mutate}
denvM <- denv %>% mutate(pH2 = pH + 1)
denvM
```

---
# Mutate
<br>


```{R}
denvM2 <- denv %>% mutate(index = 2*nit + pho + amm)
denvM2
```


---
# Mutate

```{R}
denvM3 <- denv %>%
  select(dfs, alt, pH, nit, pho, amm) %>%
  dplyr::filter(alt > 400) %>%
  mutate(pH2 = pH + 1) %>%
  mutate(index = 2*nit + pho + amm)
denvM3
```

---
# Mutate

```{R}
model <- denv %>%
  select(dfs, alt, pH, nit, pho, amm) %>%
  dplyr::filter(alt > 400) %>%
  mutate(pH2 = pH + 1) %>%
  mutate(index = 2*nit + pho + amm) %>%
  lm(index ~ pH2, data = .)
summary(model)
```

---
class: inverse, center, middle

# Questions?

## <i class="fa fa-question-circle-o" aria-hidden="true"></i>




---
# Join
<br>

--


```{R}
dfis <- doubs$fish
head(denv, 4)
head(dfis, 4)
```

---
# Join
<br>

```{R}
denv <- denv %>% mutate(idSite = 1:nrow(denv))
head(denv, 4)

dfis$idSite <- 1:nrow(denv)
head(dfis, 4)
```

---
# Join
<br>

```{R}
dmerg <- denv %>% inner_join(dfis)
head(dmerg)
dim(dmerg)
```

---
# Join
<br>

### Several ways of joining data frames [(see documentation)](https://dplyr.tidyverse.org/reference/join.html)


```{R}
dmerg1 <- denv[-1,] %>% inner_join(dfis[-2,])
dim(dmerg1)
```

--

```{R}
dmerg2 <- denv[-1,] %>% right_join(dfis[-2,])
dmerg3 <- denv[-1,] %>% left_join(dfis[-2,])
dmerg4 <- denv[-1,] %>% full_join(dfis[-2,])
dim(dmerg2)
dim(dmerg3)
dim(dmerg4)
```


---
# Aggregate
<br>

--

```{R}
denv2 <- denv %>% mutate(nit2 = nit >=125)
denv2
```

---
# Aggregate
<br>

```{R}
denv2$alt2 <- "low"
denv2$alt2[denv2$alt>450] <- "medium"
denv2$alt2[denv2$alt>750] <- "high"
denv2$alt2 <- as.factor(denv2$alt2)
denv2
```


---
# Aggregate
<br>

```{R}
denv2 %>% group_by(nit2) %>% summarize(n())
denv2 %>% group_by(nit2, alt2) %>% summarize(n())
```

---
# Aggregate
<br>

```{R}
denv2 %>% group_by(nit2) %>% summarize(n())
denv2 %>% group_by(nit2, alt2) %>%
  summarize(nb_obs = n(), mean_amm = mean(amm), sd_oxy = sd(oxy))
```


---
# Write files

### Write data frames

```{R, write}
write.csv(dmerg, "output/dmerg.csv")
write_csv(dmerg, "output/dmerg2.csv")
```
--

### Write any R objects

```{R}
saveRDS(doubs, "output/doubs.rds")
# readRDS("output/dmerg.rds")
write_rds(doubs, "output/doubs.rds")
# read_rds
```







---
class: inverse, center, middle

# Data visualization

## <i class="fa fa-bar-chart" aria-hidden="true"></i>


---
# Data visualization
<br>

## [Material +](https://insileco.github.io/Visualisation-SentinelleNord/#1)

## [bookdown](https://bookdown.org/)


---
# Components
<br>

.pull-left[
- "a chart is worth a thousand words"
]

.pull-right[

```{r, echo=FALSE}
<<load_data>>
<<component_1>>
```
]


---
# Components
<br>

.pull-left[
- "a chart is worth a thousand words"
- plot window
]

.pull-right[

```{r echo=FALSE}
<<load_data>>
<<component_2>>
```
]

---
# Components
<br>

.pull-left[
- "a chart is worth a thousand words"
- plot window
- plot region
]


.pull-right[
```{r echo=FALSE}
<<load_data>>
<<component_3>>
```
]

---
# Components
<br>

.pull-left[
- "a chart is worth a thousand words"
- plot window
- plot region
- data
]


.pull-right[
```{r echo=FALSE}
<<load_data>>
<<component_4>>
```
]

---
# Components
<br>

.pull-left[

- "a chart is worth a thousand words"
- plot window
- plot region
- data
- axes
]

.pull-right[

```{r echo=FALSE}
<<load_data>>
<<component_5>>
```
]

---
# Components
<br>

.pull-left[

- "a chart is worth a thousand words"
- plot window
- plot region
- data
- axes
- title
]


.pull-right[
```{r echo=FALSE}
<<load_data>>
<<component_6>>
```
]


---
# Components
<br>

.pull-left[
- "a chart is worth a thousand words"
- plot window
- plot region
- data
- axes
- titles
- legend
]


.pull-right[
```{r echo=FALSE}
<<load_data>>
<<component_7>>
```
]




---
# graphics vs grid
<br>

.center[![:scale 80%](images/Murrell2015.jpg)]

Murrell, P. (2015) [The gridGraphics Package]("https://journal.r-project.org/archive/2015-1/murrell.pdf"). The R Jounal.


---
# Workflows


### Base plot

```R
dev(...)
par(...)
plot(...)
fun1(...)
fun2(...)
dev.off()
```

<br>

### ggplot2

```R
myplot <- ggplot() + gg_XX1 + gg_XX2 + gg_XX3
myplot
ggsave(...)
```

---
# Hundreds of packages
<br>

### [List of packages](https://insileco.github.io/wiki/rgraphpkgs/)
### [r-graph-gallery](https://www.r-graph-gallery.com/)
### [data-to-viz](https://www.data-to-viz.com/)
### [Cookbook for R](http://www.cookbook-r.com/Graphs/)

---
# Basic plots

.pull-left[

```{R}
# denv as used above
plot(x = denv2$alt,
  y = denv2$amm)
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt, y = amm)) +
  geom_point()
p
```
]


---
# Basic plots

.pull-left[

```{R}
plot(x = denv2$alt,
  y = denv$amm,
  type = "l")
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt, y = amm)) +
  geom_line()
p
```
]


---
# Basic plots

.pull-left[

```{R}
par(las = 1)
plot(x = denv2$alt, y = denv$amm, type = "l",
    xlab = "altitude", ylab = "amm")
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt, y = amm)) +
  geom_line()
p
```
]

---
# Basic plots

.pull-left[

```{R}
par(las = 1)
plot(x = denv2$alt, y = denv$amm, type = "l",
  xlab = "altitude", ylab = "amm")
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt, y = amm)) +
  geom_line() + xlab("altitude") +
  theme_bw()
p
```
]


---
# Basic plots

.pull-left[

```{R}
par(las = 1)
plot(x = denv2$alt, y = denv$amm, pch = 19,
  col = denv2$nit2)
```
]


.pull-right[
```{R}
p <- denv2 %>% ggplot(aes(x = alt, y = amm,
  colour = nit2)) + geom_point() +
  xlab("altitude") +
  theme_bw()
p
```
]


---
# Basic plots


```{R}
colors()[1:50]
library(RColorBrewer)
```

---
# Basic plots

.pull-left[

```{R}
par(las = 1)
plot(x = denv2$alt, y = denv$amm, pch = 19,
     xlab = "altitude", ylab = "amm",
     col = c("salmon1", "turquoise2")[denv2$nit2+1],
     cex = 2)
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt, y = amm, colour = nit2)) +
  geom_point(size = 3) +
  xlab("altitude") + theme_bw()
p
```
]



---
# Basic plots

.pull-left[

```{R}
par(las = 1, mar = c(4,4,1,1))
plot(x = denv2$alt, y = denv$amm, pch = 19,
     xlab = "altitude", ylab = "amm",
  col = c("salmon1", "turquoise2")[denv2$nit2+1],
  cex = 1.5)
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt, y = amm, colour = nit2)) +
  geom_point(size = 3) + xlab("altitude") +
  theme_bw()
p
```
]



---
# Export your figure
<br>

```R
png("output/figb.png", unit = "in", width = 6, height = 5, res = 300)
par(las = 1, mar = c(4,4,1,1))
plot(x = denv2$alt, y = denv$amm, pch = 19, xlab = "altitude", ylab = "amm",
  col = c("salmon1", "turquoise2")[denv2$nit2+1], cex = 1.5)
dev.off()
```

---
# Export your figure
<br>

```R
p <- denv2 %>% ggplot(aes(x = alt, y = amm, colour = nit2)) +
  geom_point(size = 3) + xlab("altitude") + theme_bw()
ggsave("output/figg.png", unit = "in", width = 6, height = 5)
```


---
# Hints
<br>

### Base plots

- remove all components and add one layer at a time
- use `?par` as well as the help of the functions you'll use

<br>

### ggplot2

- https://ggplot2.tidyverse.org/
- find the geom (`gg_XXX`) you need: [ggplot2 extensions](https://www.ggplot2-exts.org/)


---
# Other graphs?
<br>

## [Cookbook for R](http://www.cookbook-r.com/Graphs/)

## [r-graph-gallery](https://www.r-graph-gallery.com/)


---
# Boxplots

`amm` vs in `denv2`

--

### Baseplot

- `boxplot()`
- `par()`

--

### ggplot2

- `geom_boxplot()`


---
# Boxplots

.pull-left[

```{R}
par(las = 1)
boxplot(oxy~alt2, data = denv2)
```
]


.pull-right[
```{R}
p <- denv2 %>%
  ggplot(aes(x = alt2, y = oxy)) +
  geom_boxplot()
p
```
]



---
# Custom plot
<br>

- Let's create a 3-panels figure

```{R}
mat <- matrix(c(1,1,2,3), 2, 2)
mat
```


---
# Custom plot - 3 panels
<br>

.pull-left[
```R
layout(mat, widths = c(1.5, 1))
layout.show(3)
```
]

.pull-right[
```{R, fig.width = 4, fig.height = 4, echo = FALSE}
layout(mat, widths = c(1.5, 1))
layout.show(3)
```
]

---
# Custom plot - 3 panels
<br>

.pull-left[
```R
layout(mat, widths = c(1.1, 1))
par(las = 1, mar = c(4,4,1,1))
#-- Panel 1
plot(1,1)
#-- Panel 2
plot(x = denv2$alt, y = denv$amm,
  pch = 19, xlab = "altitude", ylab = "amm",
  col = c("salmon1", "turquoise2")[denv2$nit2+1], cex = 1.2)
#--  Panel 3
boxplot(amm~alt2, data = denv2, ylim = c(0, 80))
```
]

.pull-right[
```{R, fig.width = 4, fig.height = 4, echo = FALSE}
layout(mat, widths = c(1.2, 1))
par(las = 1, mar = c(4,4,1,1))
#-- Panel 1
plot(1,1)
#-- Panel 2
plot(x = denv2$alt, y = denv$amm,
  pch = 19,
  xlab = "altitude", ylab = "amm",
  col = c("salmon1", "turquoise2")[denv2$nit2+1],
  cex = 1.5)
#--  Panel 3
boxplot(amm~alt2, data = denv2,
  ylim = c(0, 80))
```
]


---
# Custom plot - Panel 1


.pull-left[
```R
plot(denv2$pho, -denv2$alt)
```
]

.pull-right[
```{R, echo = FALSE}
plot(denv2$pho, -(denv2$alt))
```
]

---
# Custom plot - Panel 1


.pull-left[
```R
par(las = 1, bty = "l")
plot(denv2$pho, -denv2$alt,
  ann = FALSE, axes = FALSE,
  type = "n")
```
]

.pull-right[
```{R, echo = FALSE}
par(las = 1, bty = "l")
plot(denv2$pho, -denv2$alt, ann = FALSE, axes = FALSE, type = "n")
```
]

---
# Custom plot - Panel 1


.pull-left[
```R
par(las = 1, bty = "l")
plot(denv2$pho, -denv2$alt,
  ann = FALSE, axes = FALSE,
  type = "n", xlim = c(0, 500),
  ylim = c(-1000, 0))
points(denv2$pho, -denv2$alt,
  pch = 19, cex = 1.1)
```
]

.pull-right[
```{R, echo = FALSE}
par(las = 1, bty = "l", xaxs = "i", yaxs = "i")
plot(denv2$pho, -denv2$alt, ann = FALSE, axes = FALSE, type = "n", xlim = c(0, 500),
ylim = c(-1000, 0))
points(denv2$pho, -denv2$alt, pch = 19, cex = 1.1)
```
]


---
# Custom plot - Panel 1


.pull-left[
```R
par(las = 1, bty = "l")
plot(denv2$pho, -denv2$alt,
  ann = FALSE, axes = FALSE,
  type = "n", xlim = c(0, 500),
  ylim = c(-1000, 0))
lines(denv2$pho, -denv2$alt,
  lwd = 1.5)
axis(1)
axis(2, at = seq(-1000, 0, 200),
labels = abs(seq(-1000, 0, 200)))
```
]

.pull-right[
```{R, echo = FALSE}
par(las = 1, bty = "l", xaxs = "i", yaxs = "i")
plot(denv2$pho, -denv2$alt, ann = FALSE, axes = FALSE, type = "n", xlim = c(0, 500),
ylim = c(-1000, -100))
lines(denv2$pho, -denv2$alt, lwd = 1.5)
axis(1)
axis(2, at = seq(-1000, 0, 200),
labels = abs(seq(-1000, 0, 200)))
```
]


---
# Custom plot - Panel 1


.pull-left[
```R
par(las = 1, bty = "l")
plot(denv2$pho, -denv2$alt,
  ann = FALSE, axes = FALSE,
  type = "n", xlim = c(0, 500),
  ylim = c(-1000, 0))
lines(denv2$pho, -denv2$alt,
  lwd = 1.5)
axis(1)
axis(2, at = seq(-1000, 0, 200),
labels = abs(seq(-1000, 0, 200)))
title(main = "A",
  xlab = "Phosphorous",
  ylab = "Altitude")
```
]

.pull-right[
```{R, echo = FALSE}
par(las = 1, bty = "l", xaxs = "i", yaxs = "i")
plot(denv2$pho, -denv2$alt, ann = FALSE, axes = FALSE, type = "n", xlim = c(0, 500),
ylim = c(-1000, -100))
lines(denv2$pho, -denv2$alt, lwd = 1.5)
axis(1)
axis(2, at = seq(-1000, 0, 200),
labels = abs(seq(-1000, 0, 200)))
title(main = "A", xlab = "Phosphorous", ylab = "Altitude")
```
]



---
# Custom plot


```{R, eval = F}
png("output/figure1.png", unit = "in", width = 7, height = 6, res = 300)
layout(mat, widths = c(1.2, 1))
par(mar = c(4,4,1,1))
#-- Panel 1
par(las = 1, bty = "l", xaxs = "i", yaxs = "i")
plot(denv2$pho, -denv2$alt, ann = FALSE, axes = FALSE, type = "n", xlim = c(0, 500),
ylim = c(-1000, -100))
lines(denv2$pho, -denv2$alt, lwd = 1.5)
axis(1)
axis(2, at = seq(-1000, 0, 200),
labels = abs(seq(-1000, 0, 200)))
title(main = "A", xlab = "Phosphorous", ylab = "Altitude")
#-- Panel 2
par(bty = "o", xaxs = "r", yaxs = "r")
plot(x = denv2$alt, y = denv$amm, pch = 19,
  xlab = "altitude", ylab = "amm",
  col = c("salmon1", "turquoise2")[denv2$nit2+1],
  cex = 1.5)
#--  Panel 3
boxplot(oxy~alt2, data = denv2)
```

---
# Custom plot

.center[![:scale 80%](output/figure1.png)]



---
# Custom plot
<br>

- Another example: https://insileco.github.io/Visualisation-SentinelleNord/#33

- See https://insileco.github.io/VisualiseR/

- Partition with ggplot2

  - [article on sthda](http://www.sthda.com/english/wiki/ggplot2-facet-split-a-plot-into-a-matrix-of-panels)
  - [see patchwork](https://github.com/thomasp85/patchwork)










---
class: inverse, center, bottom
background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/BlankMap-World_gray.svg/1405px-BlankMap-World_gray.svg.png)
background-size: contain

# Mapping with R ![:faic](map)
 <br>


---
# Overview of the section

```{r, echo = FALSE}
library(sf)
library(raster)
library(vegan)
library(mapview)
library(RColorBrewer)
opts_chunk$set(
  dpi = 72
)
```


<br>

<img src="images/todo.png" style="float:right;width:170px;margin: 0px 0px">

1. Why mapping in R?

2. Spatial data & Coordinate reference systems

3. Vector data with **`sf`**

4. Raster data with **`raster`**

5. Thematic maps

6. Interactive maps

7. Questions, discussion, and use of your data

---
# Packages for this section

<br>

```{r, eval = F}
library(sf) # spatial vector data

library(raster) # spatial raster data

library(RColorBrewer) # colors

library(mapview) # interactive maps
```

---
# Why mapping in Ecology?

.pull-left[
![](images/thematic-map.png)
> [R script for this map](https://mhbrice.github.io/Rspatial/Rspatial_script.html)
]


.pull-left[
1. show where your plots are

2. show the spatial distribution of your variables

3. show results of spatial analyses
]

---
# Why using R for mapping?


1. Open-source, free

2. Workflow and reproducibility

3. Quite efficient
    - well-defined spatial classes
    - can read/write/convert many formats

4. Can also be used for spatial data manipulation and analysis as a GIS [![:faic](external-link)](https://mhbrice.github.io/Rspatial/Rspatial_script.html)

---
class: inverse, center, middle
# Spatial data

---
# Vector data

<br><br>

.center[
![](images/vector-data.png)
]



---
# Raster data

<br><br>

.center[
![](images/raster-data.png)
]

---
# Geospatial data in R

.column-left[
#### Abiotic data

- [`raster`](https://cran.r-project.org/web/packages/raster/index.html)
- [`marmap`](https://github.com/ericpante/marmap)
- [`rnoaa`](https://github.com/ropensci/rnoaa)
- [`rWBclimate`](https://github.com/ropensci/rWBclimate)
- [`sdmpredictors`](https://cran.r-project.org/web/packages/sdmpredictors/index.html)
]

.column-center[
#### Biotic data

- [`rgbif`](https://github.com/ropensci/rgbif)
- [`robis`](https://github.com/iobis/robis)
- [`spocc`](https://github.com/ropensci/spocc)
]

.column-right[
#### Base maps

- [`ggmap`](https://github.com/dkahle/ggmap)
- [`mregions`](https://github.com/ropenscilabs/mregions)
- [`osmdata`](https://github.com/ropensci/osmdata)
- [`raster`](https://cran.r-project.org/web/packages/raster/index.html)
- [`rnaturalearth`](https://github.com/ropenscilabs/rnaturalearth)

]


---
class: inverse, center, middle
# Coordinate reference systems

.center[
![:scale 50%](http://gistbok.ucgis.org/sites/default/files/figure2-projections.png)
]


---
# Geographic vs projected CRS

```{r canada, echo=F, warning=F, fig.height=4.8, fig.width=9}
can <- raster::getData("GADM", country = "CAN", level = 1, path = "data/")
can_sf <- st_as_sf(can)

qc <- can_sf[can_sf$NAME_1 == "Québec",]
qc_prj <- st_transform(qc, 32188)
qc_simple_prj <- st_simplify(qc_prj, dTolerance = 500)
qc_simple <- st_transform(qc_simple_prj, 4326)

par(mfrow=c(1,2), mar = c(2,3,2,1))
plot(st_geometry(qc_simple), main = "Geographic CRS - Lat/Lon", graticule=T, axes=T, cex.axis=0.8, las=1)
plot(st_geometry(qc_simple_prj), main = "Projected CRS - UTM", graticule=st_crs(qc_simple_prj), axes=T, cex.axis=0.8, las=1)
```

> [What are geographic coordinate systems?](http://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/about-geographic-coordinate-systems.htm)
> <br>
> [What are projected coordinate systems?](http://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/about-projected-coordinate-systems.htm)

---
# Define CRS with EPSG or proj4string

Many, many ways to represent the 3-D shape of the earth and to project it in a 2-D plane

- each CRS can be defined either by an `EPSG` or a `proj4string`

> The EPSG code is a numeric representation of a CRS, while the proj4string reprensents the full set of parameters spelled out in a string:
> <br>
> EPSG `4326` <=> proj4 `+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs`
> <br>
> EPSG `32188` <=> proj4 `+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs`

- All geographic files are created with a specific CRS - but it's not always defined!

- To find CRS in any format: [Spatial Reference](http://spatialreference.org/)

---
class: inverse, center, middle
# Vector data with `sf`

---
# Intro to Simple Features
<br>

<img src="https://user-images.githubusercontent.com/520851/34887433-ce1d130e-f7c6-11e7-83fc-d60ad4fae6bd.gif" style="float:right;width:150px;height:150px;">


- .alert[Simple features refers to a formal standard] (ISO 19125-1:2004) that describes
how objects in the real world can be represented in computers

- .alert[`sf` objects are easy to plot, manipulate, import and export]
  - Spatial objects are stored as data frames, with the feature geometries stored in list-columns
  - `tidyverse` friendly

- .alert[GREAT documentation!] See [sf vignettes](https://cran.rstudio.com/web/packages/sf/index.html)

---
# Intro to Simple Features

.center[
![:scale 60%](images/sf-classes.png)
]

---
# Intro to Simple Features

![](images/sf_object.png)

> [sf vignette #1](https://cran.r-project.org/web/packages/sf/vignettes/sf1.html)


---
# Geospatial data in R

Let's create a thematic map of Quebec (our study area) using data ravailable in R using `getData()` from `raster`:
- Canadian provincial boundaries - vector data
- Climate data - raster data


```{r getdata, eval = FALSE}
# Create a new directory
dir.create("data")

can <- getData("GADM", country = "CAN", level = 1, path = "data")

can
```

```{r, echo=F}
can
```

---
# Prep vector data

Convert from `sp` (`sf`'s ancester) to `sf` objects to facilitate manipulation

```{r st_sf, eval = F}
can_sf <- st_as_sf(can)

can_sf[1:3,]
```

```{r, echo = F}
can_sf[1:3,]
```

---
# Prep vector data

Retrieve Quebec and surrounding provinces

```{r getQc, message = F}
neigh <- c("Québec", "Ontario", "Nova Scotia",
           "New Brunswick", "Newfoundland and Labrador")
qc_neigh <- dplyr::filter(can_sf, NAME_1 %in% neigh)

# or using base R
# qc_neigh <- can_sf[can_sf$NAME_1 %in% neigh,]

qc_neigh
```



---
# Prep vector data

Change projection for a better representation of Quebec.

> Here, I chose EPSG 32188 which corresponds to NAD83 - MTM zone 9

```{r qc_proj, message = F}
qc_neigh_prj <- st_transform(qc_neigh, crs = 32188)

qc_neigh_prj
```

--
It would take a while to plot because there is a lot of unnecessary details, so
we can simplify the shape of the polygons using `st_simplify()`.

```{r simplify}
qc_neigh_simple <- st_simplify(qc_neigh_prj,
                               dTolerance = 1000) # simplify geometry at a 1km scale)
```

---
# Simple plot

Instead of creating a single map, the default plot of `sf` object creates multiple maps (one per attribute). This is often useful for exploring the spatial distribution of different variables.

```{r base_plot, message = FALSE, fig.height=6, fig.width=6, echo = -1}
par(mypar)
plot(qc_neigh_simple)
```

---
# Simple plot

```{r map_1, echo = -1, fig.width=9, fig.height=7}
par(mypar)
# retrieve Québec only
qc_simple <- dplyr::filter(qc_neigh_simple, NAME_1=="Québec")

plot(st_geometry(qc_neigh_simple), col = "grey65")
plot(st_geometry(qc_simple), col = "blue3", add = TRUE)
```

---
# Create a layer of `MULTIPOINTS`

- We sampled vegetation in 100 plots across Québec;
- We want to plot them with points proportional to their species richness.
- Let's create a data frame with coordinates + random values.

```{r points, message = F}
# Sample random points from our study area
sample_pts <- st_sample(x = qc_simple, size = 100)

# Create an attribute of fake species richness (with 5 to 50 species per plot)
richness <- sample(x = 5:50, size = length(sample_pts), replace = TRUE)

sample_pts <- st_sf(sample_pts, richness = richness)

sample_pts
```

---
# Get bioclimatic rasters

- Assuming we are interested in the latitudinal temperature gradient, we add a
raster of mean annual temperature (`bio1`) as a background to our map.

- Let's use a low resolution so it does not take too long to plot.

```{r temp, message = FALSE, fig.width=9}
bioclim <- getData("worldclim", var = "bio", res = 10, path = "data")

# There are 19 layers in this raster.
plot(bioclim)
```


---
# Prep raster data

Look at the annual mean temperature raster data, `bio1`:

```{r bio1}
bioclim$bio1
```

--

We need to divide by 10 (because Worldclim temperature data are in °C * 10)

```{r bio1_prep, message = F}
temp <- bioclim$bio1/10

temp
```

---
# Prep raster data - projection

Change projection to match with the polygons using `projectRaster()`.

- `projectRaster()` requires the PROJ.4 format of the CRS:

```{r}
st_crs(qc_simple)$proj4string
```


```{r raster_prj, message = F}
temp_prj <- projectRaster(temp, crs = st_crs(qc_simple)$proj4string)
```

---
# Prep raster data - crop and mask

1. `crop()` decreases the extent of a raster using the extent of another spatial object. `crop()` expects a `sp` object, so we need to transform the polygon first.
2. `mask()` keeps the raster values only in the area of interest and set the rest to `NA`.

```{r crop}
temp_crop <- crop(temp_prj, as(qc_simple, "Spatial"))
temp_mask <- mask(temp_crop, qc_simple)
```

```{r, echo = -1, fig.width=8, fig.height=4.5}
par(mypar)
par(mfrow = c(1,2))
raster::plot(temp_crop, main = "crop")
raster::plot(temp_mask, main = "mask")
```

---
class: inverse, center, middle

# Thematic map


---
# Creating a simple layout

```{r layout}
my.layout <- layout(matrix(1:2, 2), heights = c(1,.2))
layout.show(my.layout)
```

---
# Define color palette

Palette of color for the temperature raster using `brewer.pal()` and `colorRampPalette()`

```{r color, echo = -1, fig.height=2.5}
par(mar=c(4,1,.5,1))
display.brewer.pal(11, "RdYlBu")

mypal1 <- rev(brewer.pal(11, "RdYlBu"))
mypal1
mypal2 <- colorRampPalette(mypal1)
mypal2(16)

mypal <- mypal2(200)
```

---
# Step by step thematic map

Plot neighbor provinces as background

```{r, fig.width = 5.5, fig.height = 6}
layout(matrix(1:2, 2), heights = c(1,.2))
par(las = 1, xaxs='i', yaxs='i', mar = c(2,3,0,0))

plot(st_geometry(qc_neigh_simple),
     col = '#b5cfbd', border = 'grey50',
     axes = TRUE, graticule = TRUE) # add graticules
```



---
# Step by step thematic map

Add the temperature raster
```{r, echo = 4, fig.width = 5.5, fig.height = 6}
layout(matrix(1:2, 2), heights = c(1,.2))
par(las = 1, xaxs='i', yaxs='i', mar = c(2,3,0,0))
plot(st_geometry(qc_neigh_simple),
     col = '#b5cfbd', border = 'grey50',
     axes = TRUE, graticule = TRUE) # add graticules
raster::image(temp_mask, add = TRUE, col = mypal)
```

---
# Step by step thematic map

Add the Quebec polygon's boundary on top

```{r, echo = 5, fig.width = 5.5, fig.height = 6}
layout(matrix(1:2, 2), heights = c(1,.2))
par(las = 1, xaxs='i', yaxs='i', mar = c(2,3,0,0))
plot(st_geometry(qc_neigh_simple),
     col = '#b5cfbd', border = 'grey50',
     axes = TRUE, graticule = TRUE) # add graticules
raster::image(temp_mask, add = TRUE, col = mypal)
plot(st_geometry(qc_simple), add = TRUE,
     border = 'grey15', lwd = 1.4)
```


---
# Step by step thematic map

Add sample points with size proportional to their species richness
```{r, echo = 6, fig.width = 5.5, fig.height = 6}
layout(matrix(1:2, 2), heights = c(1,.2))
par(las = 1, xaxs='i', yaxs='i', mar = c(2,3,0,0))
plot(st_geometry(qc_neigh_simple),
     col = '#b5cfbd', border = 'grey50',
     axes = TRUE, graticule = TRUE) # add graticules
raster::image(temp_mask, add = TRUE, col = mypal)
plot(st_geometry(qc_simple), add = TRUE,
     border = 'grey15', lwd = 1.4)
plot(st_geometry(sample_pts), add = TRUE, pch = 21,
     bg = "#63636388", col = "grey15", lwd = 1.4,
     cex = sample_pts$richness/25) # Size proportional to richness
```


---
# Step by step thematic map

Create a color legend manually

```{r, echo = -1, fig.height=5}
par(mypar)
val <- range(values(temp_mask), na.rm = TRUE)
val

mat <- as.matrix(seq(val[1], val[2], length = 200))

image(x = mat[,1], y = 1, z = mat, col = mypal, axes = FALSE, ann = FALSE)
axis(1)
mtext(side = 1, line = 1.8, text = 'Mean annual temperature (°C)')
```

---
# Step by step thematic map

Add the color legend under the map
```{r, echo = 7:9, fig.width = 5.5, fig.height = 6}
layout(matrix(1:2, 2), heights = c(1,.2))
par(las = 1, xaxs='i', yaxs='i', mar = c(2,3,0.1,0.1))
plot(st_geometry(qc_neigh_simple),
     col = '#b5cfbd', border = 'grey50',
     axes = TRUE, graticule = TRUE) # add graticules
raster::image(temp_mask, add = TRUE, col = mypal)
plot(st_geometry(qc_simple), add = TRUE,
     border = 'grey15', lwd = 1.4)
plot(st_geometry(sample_pts), add = TRUE, pch = 21,
     bg = "#63636388", col = "grey15", lwd = 1.4,
     cex = sample_pts$richness/25) # Size proportional to richness
par(mar = c(3,4,1,4))
raster::image(x = mat[,1], y = 1, z = mat, col = mypal, axes = FALSE, ann = FALSE)
axis(1, cex.axis = .8)
mtext(side = 1, line = 1.8, text = 'Mean annual temperature (°C)')
```

---
class: inverse, center, middle
# Interactive map

---
# Interactive map


```{r mapview1, fig.width=12.4, fig.height=6.5}
mapView(qc_simple)
```


---
# Interactive map

```{r mapview_pts, fig.width=12.4, fig.height=6.5}
mapView(sample_pts, layer.name = "Species richness")
```

---
# Interactive map

```{r mapview3, fig.width=12.4, fig.height=6.5}
mapView(sample_pts, col.regions = "red", cex = 'richness', legend = FALSE,
        map.types = "Esri.WorldImagery")
```

---
# Great online resources

.pull-left[
#### Good tutorials for spatial data in R

- [Raster analysis in R](https://mgimond.github.io/megug2017/)
- [Geocomputation with R](https://geocompr.robinlovelace.net/intro.html)
- [Spatial data in R](https://github.com/Pakillo/R-GIS-tutorial/blob/master/R-GIS_tutorial.md)
- [Document par Nicolas Casajus (fr)](https://qcbs.ca/wiki/_media/gisonr.pdf)
- [r-spatial](http://r-spatial.org/)
- [Tutorial on datacamp](https://www.datacamp.com/courses/spatial-analysis-in-r-with-sf-and-raster)
- [R in space - Insileco](https://insileco.github.io/2018/04/14/r-in-space---a-series/)
- [Geospatial analyses & maps with R](https://mhbrice.github.io/Rspatial/Rspatial_script.html)

#### Get free data

- [free data at country level](http://www.diva-gis.org/gdata)
- [Quebec free data](http://mffp.gouv.qc.ca/le-ministere/acces-aux-donnees-gratuites/)
- [find more spatial data](https://freegisdata.rtwilson.com/)
- [create shapefile on line](http://geojson.io/)
- EPSG: [link1](http://spatialreference.org/); [link2](http://epsg.io/)

]

.pull-right[

#### Maps in R

- [Introduction to visualising spatial data in R](https://cran.r-project.org/doc/contrib/intro-spatial-rl.pdf)
- [Geocomputation with R](https://geocompr.robinlovelace.net/adv-map.html)
- [choropleth](https://cengel.github.io/rspatial/4_Mapping.nb.html)
- [leaflet](https://rstudio.github.io/leaflet/)
- [Mapview](https://r-spatial.github.io/mapview/index.html)
- [tmap](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-nutshell.html)
- [plotly](https://plot.ly/python/maps/)
- [Animated maps](https://insileco.github.io/2017/07/05/animations-in-r-time-series-of-erythemal-irradiance-in-the-st.-lawrence/)

#### `sf` manipulations

- [sf vignette #4](https://cran.r-project.org/web/packages/sf/vignettes/sf4.html)
- [Geocomputation with R](https://geocompr.robinlovelace.net/attr.html)
- [Attribute manipulations](https://insileco.github.io/2018/04/09/r-in-space---attribute-manipulations/)
- [Tidy spatial data in R](http://strimas.com/r/tidy-sf/)

]




---
class: inverse, center, middle

# Introduction to ordination: PCA+RDA

## <i class="fa fa-sitemap" aria-hidden="true"></i>




---
# Ordination of multivariate data

<br>

.center[![:scale 70%](images/ordi1.png)]

---
# Ordination of multivariate data

<br>

.center[![:scale 70%](images/ordi2.png)]

---
# Ordination of multivariate data

<br>

.center[![:scale 70%](images/ordi3.png)]

---
# Unconstrained vs constrained ordinations

### Unconstrained ordination

- Reveal the main patterns in multivariate data (e.g. matrix of species abundance at different sites or matrix of environmental variables at different sites)
- Describe relationship among variables of one matrix.
- Descriptive method: no statistical test

### Constrained/canonical ordination

- Explicitly puts into relationship two matrices: one dependent matrix and one explanatory matrix.
- This approach combines the techniques of ordination and multiple regression.
- Explanatory method: statistical test

<br>
*Both types of ordination are based upon a comparison of all possible pairs of objects (or descriptors) using association measures.*

---
# Unconstrained vs constrained ordinations

<br>

| Response data | Explanatory variables  | Analysis            |
|---------------|------------------------|---------------------|
| 1 variable    | 1 variable             | Simple regression   |
| 1 variable    | m variables            | Multiple regression |
| p variables   | -                      | Simple ordination   |
| p variables   | m variables            | Canonical ordination|

---
# Steps to ordination

1. Explore your data:
  - multivariate data, species abundance or environmental variables, 1 or 2 matrices
2. Prep your data
3. Perform an ordination analysis:
  - Unconstrained to describe 1 matrix
  - Constrained to explain the species matrix by the environmental matrix
4. Interpret the output
5. Plot
6. For constrained ordination: variable selection + test of significance

---
# Packages for this section

```{r, eval = F}
library(vegan) # for all multivariate methods

library(ade4) # for the Doubs dataset

library(scales) # for color transparency
```

---
class: inverse, center, middle
# Explore data

---
# Doubs River Fish Dataset

.pull-left[

Verneaux (1973) dataset:
- characterization of fish communities
- 27 different species
- 30 different sites
- 11 environmental variables

Load the Doubs River species data

```{r}
data(doubs) # available in ade4
spe <- doubs$fish
env <- doubs$env
```

]

.pull.right[
![:scale 50%](images/DoubsRiver.png)
]

---
# Explore environmental data

```{r, echo = T}
head(env) # first 6 rows
```

---
# Explore environmental data

```{r, fig.width=11, fig.height=10, echo = -1}
par(mar=c(0,0,0,0))
pairs(env)
```

---
# Explore species data

```{r}
head(spe)
```

---
# Explore species data

Take a look at the distribution of species frequencies

```{r, fig.width=8, echo = -1}
par(mypar)
ab <- table(unlist(spe))
barplot(ab, las = 1, col = grey(5:0/5),
        xlab = "Abundance class", ylab = "Frequency")
```

.alert[Note the proportion of 0s.]

---
# Double zero

**How do we interpret the double absence of species in a matrix of species abundances (or presence-absence)?**

<img style="float: right; width:50%;margin: 1%" src="images/double-zero.png">
- the *presence* of a species in 2 sites indicates ecological resemblance between these 2 sites
  - the sites provide a set of minimal conditions allowing the species to survive.

- the *absence* of a species from 2 sites cannot be interpreted as a resemblance because it may be due to a variety of causes: competition, several dimensions of the niche (pH, light, temperature...), random dispersal process.



.alert[A measured 0 (e.g 0mg/L, 0°C) is not the same than a 0 representing an absence of observation]

---
class: inverse, center, middle
# Data preparation

---
# Distance measures

.comment[Ordination analysis are based on the comparison of all possible pairs of objects.

PCA and RDA are based on the Euclidean distance.]

<br>

Here we want to measure the ecological resemblance (distance or similarity) among sites.

<img style="float: right; width:30%;margin: 1%" src="images/distMes.png">
- If we compare the sites based on their **environmental variables**, we can use the **Eucidean distance**

- If we compare the sites based on their **species composition**, we don't want to consider double-zero as a similarity. **Euclidean distance is not appropriate**.
  - Solution 1: **Pre-transform** the species matrix to trick the PCA or RDA to use an appropriate distance such as Hellinger.
  - Solution 2: Run a correspondance analysis (CA) which is based on the Chi-square distance
  - Solution 3: Compute a distance matrix from the species matrix and run a PCoA

---
# Standardization of environmental data

Standardizing environmental variables is necessary as you cannot compare the effects of variables with different units

```{r}
env.z <- decostand(env, method = "standardize")
# env.z <- scale(env)
```

Standardization centers (mean $\mu$ = 0) and scales (standard deviation $\sigma$ = 1) the variables

```{r}
apply(env.z, 2, mean)

apply(env.z, 2, sd)
```

---
# Transforming species community data

<br>

.center[
![](images/transformation.png)]

---
# Transforming species community data

.alert[Hellinger transformation]

```{r}
spe.hel <- decostand(spe, method = "hellinger")
```

Other transformation methods:

`method = "chi.square"` ![:faic](arrow-right) **$\chi^2$**. When using this transformation in a PCA, the result will be similar to the result of a correspondance analysis (CA)

`method = "normalize"` ![:faic](arrow-right) **Chord transformation**

`method = "total"` ![:faic](arrow-right)  **Species profile transformation**

> According to [Legendre & Gallagher](http://adn.biol.umontreal.ca/~numericalecology/Reprints/Legendre_&_Gallagher.pdf): The Hellinger and chord transformations appear to be the best for general use with species data.

---
class: inverse, center, middle
# Unconstrained ordination
## PCA



---
# Principal Component Analysis (PCA)

- Starting from a multidimensional sites x descriptors matrix
  - where the descriptors can be species abundance (or presence-absence) or environmental variables

- A PCA will preserve the maximum amount of variation in the data in a reduced number of dimensions (usually we use the first 2 dimensions)

- The resulting, synthetic variables are orthogonal (i.e. perpendicular and therefore uncorrelated)

.center[
![:scale 70%](images/pca_3d_2d.jpg)]

---
# PCA - Multidimensional case

<br/><br/>

- **PC1** ![:faic](arrow-right) axis that maximizes the variance of the points that are projected perpendicularly onto the axis.
- **PC2** ![:faic](arrow-right) must be perpendicular to PC1, but the direction is again the one in which variance is maximized when points are perpendicularly projected
- **PC3** ![:faic](arrow-right) and so on: perpendicular to the first two axes

<br/>

.red[For a matrix containing *p* descriptors, a PCA produces *p* axes which are ordered according to the % of variation of the data they explain]


---
# PCA - Let's try it on the fish dataset!

- For both PCA and RDA, we can use the `rda()` function from the vegan package
  - `rda(Y ~ X)` or `rda(Y, X)` ![:faic](arrow-right) RDA
  - `rda(Y)` or `rda(X)` ![:faic](arrow-right) PCA

---
# PCA

- Run a PCA on the Hellinger-transformed fish data and extract the results

```{r, output.lines = 1:20}
spe.h.pca <- rda(spe.hel)

summary(spe.h.pca)
```

---
#PCA - Interpretation of Output

```{r, output.lines = 2:8}
summary(spe.h.pca)
```

- `Inertia` ![:faic](arrow-right) general term for "variation" in the data.
- Total variance of the dataset (here the fish species) = 0.5023
- In PCA, note that the "Total" and "Unconstrained" portion of the inertia is identical

---
# PCA - Interpretation of Output

```{r, output.lines = 2:16}
summary(spe.h.pca)
```

- `Eigenvalue` ![:faic](arrow-right) measures the amount of variation represented by each ordination axe (Principal Component or PC)
- One eigenvalue associated to each PC (in this output there are 27 PCs, as this is the number of species)


<br/>

.center[**0.2491 + 0.06592 + ... = 0.5023 Total inertia**]

---
# PCA - Interpretation of Output

```{r, output.lines = 2:16}
summary(spe.h.pca)
```


- `Proportion Explained` ![:faic](arrow-right) proportion of variation accounted for, by dividing the eigenvalues by the total inertia.

<br/>

.center[**0.2491/0.5023 = 0.4959 or 49.59%**]


---
# PCA - Interpretation of Output

```{r, output.lines = 40:50}
summary(spe.h.pca)
```


- `Species scores` ![:faic](arrow-right) coordinates of all descriptors in the multidimensional space of the PCA.

<br>

- Species always refers to your descriptors (the columns in your matrix), here the fish species. Even if you run a PCA on environmental variables, the descriptors will still be called Species scores

---
# PCA - Interpretation of Output

```{r, output.lines = 72:82}
summary(spe.h.pca)
```

- `Site scores` ![:faic](arrow-right) coordinates of all sites in the multidimensional space of the PCA.

<br>

- Site refers to the rows in your dataset, here the different sites along the Doubs river (but it can be points in time, etc)




---
# Selecting Important PCs

Select PCs which capture more variance than the average (Kaiser-Guttman criterion)


```{r, echo = -1, fig.width=10, fig.height = 5.5}
par(mypar)
ev <- spe.h.pca$CA$eig # extract eigenvalues
barplot(ev, main = "Eigenvalues", col = "grey", las = 2)
abline(h = mean(ev), col = "red3", lwd = 2)
```


---
# PCA - environmental variables

We can also run PCAs on standardized environmental variables, to compare environmental conditions of sites or how environmental variables are correlated...

- Run a PCA on the standardized environmental variables and extract the results
```{r, output.lines = 1:20}
env.pca <- rda(env.z)
summary(env.pca)
```

---
# PCA - environmental variables

- Plot the eigenvalues above average

```{r, echo = -1, fig.width=10, fig.height = 5.5}
par(mypar)
ev <- env.pca$CA$eig # extract eigenvalues
barplot(ev, main = "Eigenvalues", col = "grey", las = 2)
abline(h = mean(ev), col = "red3", lwd = 2)
```

---
# PCA - Visualization

The abundance of information produced by PCA is easier to understand and interpret using biplots to visualize patterns

- We can produce a quick biplot of the PCA using the function `biplot()` in base R

```{r, echo = -1}
par(mypar)
biplot(spe.h.pca)
```

---
# PCA - Scaling

```{r, echo = -1, fig.height=5, fig.width=10}
par(mypar, mfrow = c(1,2))
biplot(spe.h.pca, scaling = 1, main = "Scaling 1 = distance biplot")
biplot(spe.h.pca, scaling = 2, main = "Scaling 2 = correlation biplot")
```

- In a PCA, we interpret the .purple[**correlation among species**] by looking at the angles among their arrows, while we interpret the .purple[**distance among sites**].

- However, we cannot optimally display sites and species together in a PCA biplot.

---
# PCA - Scaling

```{r, echo = FALSE, fig.height=4.5, fig.width=9}
par(mypar, mfrow = c(1,2))
biplot(spe.h.pca, scaling = 1, main = "Scaling 1 = distance biplot")
biplot(spe.h.pca, scaling = 2, main = "Scaling 2 = correlation biplot")
```

.pull-left[
**Scaling 1**:
- distances among objects are approximations of Euclidean distances;
- the angles among descriptors vector are meaningless.

.alert[Best for interpreting relationships among objects (sites)!]
]

.pull-right[**Scaling 2** (Default):
- angles between descriptors vectors reflect their correlations;
- distances among objects are not approximations of Euclidean distances.

.alert[Best for interpreting relationships among descriptors (species)!]
]

---
# Customized biplot
<br>

- Extract species and site scores along the 1st and 2nd PC:
```{r}
spe.scores <- scores(spe.h.pca, display = "species", choices = 1:2)

site.scores <- scores(spe.h.pca, display = "sites", choices = 1:2)
```

- Extract % of variation on the 1st and 2nd PC:
```{r}
prop1 <- round(spe.h.pca$CA$eig[1]/sum(spe.h.pca$CA$eig)*100, 2)

prop2 <- round(spe.h.pca$CA$eig[2]/sum(spe.h.pca$CA$eig)*100, 2)
```

---
# Customized biplot

Empty plot with informative axis labels
```{r, echo = -1}
par(mypar)
plot(spe.h.pca, type = "none",
     xlab = paste0("PC1 (", prop1, "%)"),
     ylab = paste0("PC2 (", prop2, "%)"))
```

---
# Customized biplot

Add points for sites
```{r, echo = 3}
par(mypar)
plot(spe.h.pca, type = "none",
     xlab = paste0("PC1 (", prop1, "%)"),
     ylab = paste0("PC2 (", prop2, "%)"))
points(site.scores,
       pch = 21, bg = "steelblue", cex  = 1.2)
```

---
# Customized biplot

Add arrows for species
```{r, echo = 4}
par(mypar)
plot(spe.h.pca, type = "none",
     xlab = paste0("PC1 (", prop1, "%)"),
     ylab = paste0("PC2 (", prop2, "%)"))
points(site.scores,
       pch = 21, bg = "steelblue", cex  = 1.2)
arrows(x0 = 0, y0 = 0,
       x1 = spe.scores[,1], y1 = spe.scores[,2],
       length = 0.1) # size of arrow head
```

---
# Customized biplot

Add labels for species
```{r, echo = 5}
par(mypar)
plot(spe.h.pca, type = "none",
     xlab = paste0("PC1 (", prop1, "%)"),
     ylab = paste0("PC2 (", prop2, "%)"))
points(site.scores,
       pch = 21, bg = "steelblue", cex  = 1.2)
arrows(x0 = 0, y0 = 0,
       x1 = spe.scores[,1], y1 = spe.scores[,2],
       length = 0.1)
text(spe.scores[,1], spe.scores[,2],
     labels = rownames(spe.scores),
     col = "red3", cex = 0.8)
```


---
# Customized biplot

Complete code for the biplot
```{r, eval = F}
plot(spe.h.pca, type = "none",
     xlab = paste0("PC1 (", prop1, "%)"),
     ylab = paste0("PC2 (", prop2, "%)"))
points(site.scores,
       pch = 21, bg = "steelblue", cex  = 1.2)
arrows(x0 = 0, y0 = 0,
       x1 = spe.scores[,1], y1 = spe.scores[,2],
       length = 0.1)
text(spe.scores[,1], spe.scores[,2],
     labels = rownames(spe.scores),
     col = "red3", cex = 0.8)
```

---
class: inverse, center, middle

# Constrained ordinations

## Redundancy analysis - RDA

---
# RDA

- RDA = combination of multiple regressions and a PCA.

- It allows us to identify and test relationships between a response matrix and explanatory matrix or matrices

.center[ ![:scale 60%](images/RDA_mat.png)]

- Explanatory variables can be quantitative, qualitative, or binary (0/1).

<br>
- .alert[Transform] species data and .alert[standardize] quantitative variables prior to running a RDA.

---
# Run the RDA

- Model the effect of all environmental variables on fish community composition

```{r}
spe.rda <- rda(spe.hel ~., data = env.z) # "~." indicates all variables
# or spe.rda <- rda(X = spe.hel, Y = env.z)
```

- .comment[It is better to use the formula interface which is more flexible (allows for factors and interaction among variables)], for example:
  - `rda(spe.hel ~ var1 + var2*var3 + fac, data = env.z)`
- You can also control for a group of variables, for example you are interested in the effect var1,2,3 while holding constant var4,5:
  - `rda(spe.hel ~ var1 + var2*var3 + Condition(var4 + var5), data = env.z)`

---
# RDA output in R

```{r, output.lines = 1:9}
summary(spe.rda)
```

- **`Constrained Proportion`** ![:faic](arrow-right) variance of the response matrix explained by the environmental matrix
 - .alert[(0.3557/0.5023 = 70.81%)]
 - Equivalent of unadjusted R2
- **`Unconstained Proportion`** ![:faic](arrow-right) unexplained variance in the response matrix (residuals)
  - .alert[(0.1467/0.5023 = 29.21%)]




---
# RDA output in R

```{r, output.lines = 11:25}
summary(spe.rda)
```

- **`Eigenvalues, and their contribution to the variance`** ![:faic](arrow-right) eigenvalues for the canonical axes (RDA1 to RDA11) and the unconstrained axes (PC1 to PC18), as well as the cumulative proportion of .purple[**variance explained by the RDA axes**] and .purple[**represented by the residual PC axes**].
- The first 2 RDA axes cumulatively explain 55% of the fish community variance.

---
# Selecting variables

Using .alert[stepwise selection], we can select the explanatory variables that are significant.


```{r}
# Forward selection of variables:
mod0 <- rda(spe.hel ~ 1, data = env.z)  # Model with intercept only
rda.sel <- ordiR2step(mod0, # lower model limit
               scope = formula(spe.rda), # upper model limit (full model)
               direction = "forward", # could be backward or both
               R2scope = TRUE, # can't surpass the full model's R2
               step = 1000,
               trace = FALSE) # change to TRUE to see the selection process!
```

.comment[Here, we are essentially adding one variable at a time, and retaining it if it significantly increases the model's adjusted R2.]

---
# Selecting variables

- Which variables are retained by the forward selection?
```{r}
rda.sel$call
```


- What is the **adjusted R2** of the RDA with the selected variables?
```{r}
RsquareAdj(rda.sel)
```

How would you report these results in a paper?
- .comment[The selected environmental variables (dfs + oxy + bdo) explain .alert[51.43%] of the variation in fish community composition in the 30 sites along the Doubs river.]
- Note: you should report the adjusted R2 which takes into account the number of explanatory variables.

---
# Significance testing

Use `anova.cca()` to test the significance of your RDA.
```{r}
anova.cca(rda.sel, step = 1000)
```

You can also test the significance of each axis!
```{r, eval = F}
anova.cca(rda.sel, step = 1000, by = "axis")
```

... and of each variable!
```{r, eval = F}
anova.cca(rda.sel, step = 1000, by = "term")
```

.center[
.alert[![:faic](exclamation-triangle) If your global test is not significant, RDA results should not be interpreted!]
]


---
# RDA - Visualization

RDA allows a **simultaneous visualization** of your response and explanatory variables

```{r, echo=-1, fig.width=11, fig.height=4.5}
par(mfrow = c(1,2), mar=c(4,4,0,1), cex = 1.5)
ordiplot(rda.sel, scaling = 1, type = "text")
ordiplot(rda.sel, scaling = 2, type = "text")
```

.pull-left[
**Scaling 1** distances among objects reflect their similarities
]

.pull-right[
**Scaling 2** angles between variables (species and explanatory variables) reflect their correlation
]

---
# RDA triplot - Scaling

### Scaling 1 – .comment[distance triplot]

.pull-left[
```{r, echo=F}
par(mypar)
ordiplot(rda.sel, scaling = 1, type = "text")
arrows(0, 0, scores(rda.sel, scaling = 1)$species[,1],
       scores(rda.sel, scaling = 1)$species[,2],
       length = .1, col = "red")
```
]

.pull-right[
- .alert[Distances among sites] approximate their Euclidean distances, i.e. sites that are close together share similar species. Idem for centroids of qualitative variables.
- .alert[Projecting a site at right angle] on a response variable or a quantitative explanatory variable approximates the value of the site along that variable.
- The .alert[angles between response and explanatory variables] reflect their correlations (*but not the angles among response variables*).
]
---
# RDA triplot - Scaling

### Scaling 2 - .comment[correlation triplot]

.pull-left[
```{r, echo = F}
par(mypar)
ordiplot(rda.sel, scaling = 2, type = "text")
arrows(0, 0, scores(rda.sel)$species[,1],
       scores(rda.sel)$species[,2],
       length = .1, col = "red")
```
]

.pull-right[
- The .alert[angles between *all* vector variables] reflect their correlations.
- Distances among sites do **not** approximate their Euclidean distances. Idem for centroids of qualitative variables.
- .alert[Projecting a site at right angle] on a response variable or a quantitative explanatory variable approximates the value of the site along that variable.
- Environmental arrows that are .alert[along the first axis and longer]  are more important to explain the variation in the community matrix.
]

---
# Customizing RDA triplot

Both `plot()` and `ordiplot()` make quick and simple ordination plots, but you can customize your plots by manually setting the aesthetics of points, text, and arrows.

- Extract species and site scores along the 1st and 2nd RDA:
```{r}
spe.scores <- scores(rda.sel, display = "species", choices = 1:2)
site.scores <- scores(rda.sel, display = "sites", choices = 1:2)
env.scores <- scores(rda.sel, display = "bp", choices= 1:2)
# default: scaling = 2
```

- Extract % of variation on the 1st and 2nd RDA:
```{r}
prop1 <- round(rda.sel$CCA$eig[1]/sum(rda.sel$CCA$eig)*100, 2)
prop2 <- round(rda.sel$CCA$eig[2]/sum(rda.sel$CCA$eig)*100, 2)
```
---
# Customizing RDA triplot

```{r, eval = F}
# Empty plot with axes
plot(rda.sel, type = "none",
     xlab = paste0("RDA1 (", prop1, "%)"),
     ylab = paste0("RDA2 (", prop2, "%)"))

# Points for sites
points(site.scores,
       pch = 19, col = alpha("grey", 0.5), cex  = 1.1)

# Arrows and text for species
arrows(x0 = 0, y0 = 0,
       x1 = spe.scores[,1], y1 = spe.scores[,2],
       length = 0.1, col = "grey15")
text(spe.scores[,1],
     spe.scores[,2]+sign(spe.scores[,2])*.02, # shift labels
     labels = rownames(spe.scores),
     col = "grey15", cex = 0.9)

# Arrows and text for environmental variables
arrows(x0 = 0, y0 = 0,
       x1 = env.scores[,1], y1 = env.scores[,2],
       length = 0.1, lwd = 1.5, col = "#CC3311")
text(env.scores[,1]+sign(env.scores[,1])*.05, # shift labels
     env.scores[,2],
     labels = rownames(env.scores),
     col = "#CC3311", cex = 1, font = 2)
```


---
# Customizing RDA triplot

```{r, echo = FALSE, fig.width=7, fig.height=7}
par(mypar)
# Empty plot with axes
plot(rda.sel, type = "none",
     xlab = paste0("RDA1 (", prop1, "%)"),
     ylab = paste0("RDA2 (", prop2, "%)"))
# Points for sites
points(site.scores,
       pch = 19, col = alpha("grey", 0.5), cex  = 1.1)
# Arrows and text for species
arrows(x0 = 0, y0 = 0,
       x1 = spe.scores[,1], y1 = spe.scores[,2],
       length = 0.1, col = "grey15")
text(spe.scores[,1],
     spe.scores[,2]+sign(spe.scores[,2])*.02,
     labels = rownames(spe.scores),
     col = "grey15", cex = 0.9)
# Arrows and text for environmental variables
arrows(x0 = 0, y0 = 0,
       x1 = env.scores[,1], y1 = env.scores[,2],
       length = 0.1, lwd = 1.5, col = "#CC3311")
text(env.scores[,1]+sign(env.scores[,1])*.05,
     env.scores[,2],
     labels = rownames(env.scores),
     col = "#CC3311", cex = 1, font = 2)
```

---
# Customizing RDA triplot

```{r, echo = 1, fig.width=7, fig.height=7}
spe.scores <- spe.scores * 1.4
# Empty plot with axes
plot(rda.sel, type = "none",
     xlab = paste0("RDA1 (", prop1, "%)"),
     ylab = paste0("RDA2 (", prop2, "%)"))

# Points for sites
points(site.scores,
       pch = 19, col = alpha("grey", 0.5), cex  = 1.1)

# Arrows and text for species
arrows(x0 = 0, y0 = 0,
       x1 = spe.scores[,1], y1 = spe.scores[,2],
       length = 0.1, col = "grey15")
text(spe.scores[,1],
     spe.scores[,2]+sign(spe.scores[,2])*.02, # shift labels
     labels = rownames(spe.scores),
     col = "grey15", cex = 0.9)

# Arrows and text for environmental variables
arrows(x0 = 0, y0 = 0,
       x1 = env.scores[,1], y1 = env.scores[,2],
       length = 0.1, lwd = 1.5, col = "#CC3311")
text(env.scores[,1]+sign(env.scores[,1])*.05, # shift labels
     env.scores[,2],
     labels = rownames(env.scores),
     col = "#CC3311", cex = 1, font = 2)
```


---
class: inverse, center, middle

# Thank you for attending this workshop!
